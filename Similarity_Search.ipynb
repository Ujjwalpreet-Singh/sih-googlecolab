{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1d2qzF4Wm2Y5H_DR7GHZyqcmm6HBM5L4o",
      "authorship_tag": "ABX9TyMM44vvYg3CJ6DcSkOjU+/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5761119b8aff4f85b78c76b1eba112a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e23ac789a9d4419989cd61f3f323e5a2",
              "IPY_MODEL_6574bf30110742479521ffd17cf0a094",
              "IPY_MODEL_be010bc32d04451bb6407623c09f7933"
            ],
            "layout": "IPY_MODEL_8f39b82477974c1186675fca2aa85fee"
          }
        },
        "e23ac789a9d4419989cd61f3f323e5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_577a885b0ed94683a91915efa7f75061",
            "placeholder": "​",
            "style": "IPY_MODEL_881f0a7fcc0344b7b21eac8be933168d",
            "value": "Batches: 100%"
          }
        },
        "6574bf30110742479521ffd17cf0a094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfe7dd7cbb9c40a9988de882b3824cb0",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_058dc691c9f1498f9d8c9b97441dd75b",
            "value": 4
          }
        },
        "be010bc32d04451bb6407623c09f7933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bac9d85163e4678ba073891e0a94e3c",
            "placeholder": "​",
            "style": "IPY_MODEL_9a24c0a56de94b97a406b44d22c9a1db",
            "value": " 4/4 [00:00&lt;00:00, 36.59it/s]"
          }
        },
        "8f39b82477974c1186675fca2aa85fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577a885b0ed94683a91915efa7f75061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "881f0a7fcc0344b7b21eac8be933168d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfe7dd7cbb9c40a9988de882b3824cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058dc691c9f1498f9d8c9b97441dd75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bac9d85163e4678ba073891e0a94e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a24c0a56de94b97a406b44d22c9a1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4873431dcd042e9b997e7e64f39ce46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17e0adf5f0a949e3bafa2f447e361031",
              "IPY_MODEL_0bb0824484b940af972dc921bed7b9f9",
              "IPY_MODEL_f7be47b26de44eeba4211273f80e2dca"
            ],
            "layout": "IPY_MODEL_568acc93c0e841aeae8c6ea94d3786c3"
          }
        },
        "17e0adf5f0a949e3bafa2f447e361031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e37355d9e04800b2a05d74bd821781",
            "placeholder": "​",
            "style": "IPY_MODEL_1d01693984d24265aca247e21334bc01",
            "value": "Batches: 100%"
          }
        },
        "0bb0824484b940af972dc921bed7b9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bce6fe302344a49a2c428aa13d8b721",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f0f89773ee441858ce75850243e61cc",
            "value": 2
          }
        },
        "f7be47b26de44eeba4211273f80e2dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc7cb95be7b493ab13d136156b325fb",
            "placeholder": "​",
            "style": "IPY_MODEL_5681020ee2694fde9b94141b3df3ef9d",
            "value": " 2/2 [00:00&lt;00:00, 37.00it/s]"
          }
        },
        "568acc93c0e841aeae8c6ea94d3786c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e37355d9e04800b2a05d74bd821781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d01693984d24265aca247e21334bc01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bce6fe302344a49a2c428aa13d8b721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f0f89773ee441858ce75850243e61cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adc7cb95be7b493ab13d136156b325fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5681020ee2694fde9b94141b3df3ef9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ujjwalpreet-Singh/sih-googlecolab/blob/main/Similarity_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PXJUbIy9Giz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9284b6-ea88-4a86-cade-a10e727eb5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-6.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.7.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.5.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.5.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.29.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.2)\n",
            "Downloading pypdf-6.4.0-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, pytesseract, pypdf, jedi\n",
            "Successfully installed jedi-0.19.2 pypdf-6.4.0 pytesseract-0.3.13 python-docx-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install pypdf python-docx pytesseract Pillow google-generativeai ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75d1f8b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2810af-8d3f-4b71-ca45-162686bf3c0f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ff2b15e",
        "outputId": "8017779a-5d07-4574-8e20-bbbe56fe1af5"
      },
      "source": [
        "import os\n",
        "import json # Added import for json\n",
        "\n",
        "# 2. Construct the full paths to the 'processed resumes' and 'processed jobs' subfolders\n",
        "resumes_folder_path = \"/content/drive/MyDrive/SIH-Project/processed_resumes\"\n",
        "jobs_folder_path = \"/content/drive/MyDrive/SIH-Project/processed-jobs\"\n",
        "\n",
        "print(f\"\\nAttempting to access resume folder: {resumes_folder_path}\")\n",
        "print(f\"Attempting to access jobs folder: {jobs_folder_path}\")\n",
        "\n",
        "# 3. List the contents of both subfolders to confirm that files are present\n",
        "print(\"\\nListing contents of 'processed resumes' folder:\")\n",
        "if os.path.exists(resumes_folder_path):\n",
        "    resume_files = [f for f in os.listdir(resumes_folder_path) if f.endswith('.txt') or f.endswith('.pdf') or f.endswith('json')]\n",
        "    if resume_files:\n",
        "        print(resume_files)\n",
        "    else:\n",
        "        print(\"No resume files found or folder is empty.\")\n",
        "else:\n",
        "    print(f\"Error: '{resumes_folder_path}' not found.\")\n",
        "    resume_files = []\n",
        "\n",
        "print(\"\\nListing contents of 'processed jobs' folder:\")\n",
        "if os.path.exists(jobs_folder_path):\n",
        "    job_files = [f for f in os.listdir(jobs_folder_path) if f.endswith('.txt') or f.endswith('.pdf') or f.endswith('json')]\n",
        "    if job_files:\n",
        "        print(job_files)\n",
        "    else:\n",
        "        print(\"No job files found or folder is empty.\")\n",
        "else:\n",
        "    print(f\"Error: '{jobs_folder_path}' not found.\")\n",
        "    job_files = []\n",
        "\n",
        "# 4. From the 'processed resumes' folder, select one resume file and read its content\n",
        "selected_resume_content = \"\"\n",
        "if resume_files:\n",
        "    # Assuming the resume is also a JSON file as per previous execution\n",
        "    selected_resume_file = os.path.join(resumes_folder_path, resume_files[0])\n",
        "    try:\n",
        "        if selected_resume_file.endswith('.json'):\n",
        "            with open(selected_resume_file, 'r', encoding='utf-8') as f:\n",
        "                resume_data = json.load(f)\n",
        "                # Extract relevant text from the resume JSON for embedding\n",
        "                # For now, let's just use the entire JSON string representation if it's complex\n",
        "                # or pick specific fields. For simplicity, we'll convert back to string.\n",
        "                # A more robust solution would be to define which fields are relevant for embedding.\n",
        "                selected_resume_content = json.dumps(resume_data) # Keep as string for embedding\n",
        "        else: # Handle .txt or .pdf files as before\n",
        "            with open(selected_resume_file, 'r', encoding='utf-8') as f:\n",
        "                selected_resume_content = f.read()\n",
        "        print(f\"\\nSuccessfully read resume file: {resume_files[0]}\")\n",
        "        print(\"First few lines of resume content:\")\n",
        "        print('\\n'.join(selected_resume_content.splitlines()[:5]))\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading resume file {selected_resume_file}: {e}\")\n",
        "else:\n",
        "    print(\"\\nNo resume files available to read.\")\n",
        "\n",
        "# 5. From the 'processed jobs' folder, iterate through all files and read their content\n",
        "job_postings_content = []\n",
        "job_postings_raw_data = [] # New list to store parsed job objects\n",
        "if job_files:\n",
        "    for job_file_name in job_files:\n",
        "        job_file_path = os.path.join(jobs_folder_path, job_file_name)\n",
        "        try:\n",
        "            if job_file_name.endswith('.json'):\n",
        "                with open(job_file_path, 'r', encoding='utf-8') as f:\n",
        "                    json_data = json.load(f)\n",
        "                    # Assuming json_data is a list of job dictionaries\n",
        "                    for job_obj in json_data:\n",
        "                        job_text = ''\n",
        "                        # Extract text for embedding - combine relevant field\n",
        "                        if 'skills' in job_obj and isinstance(job_obj['skills'], list):\n",
        "                            job_text += ' ' + ', '.join(job_obj['skills'])\n",
        "                        job_postings_content.append(job_text.strip())\n",
        "                        job_postings_raw_data.append(job_obj) # Store the original job dict\n",
        "            else: # Handle .txt or .pdf files as before\n",
        "                with open(job_file_path, 'r', encoding='utf-8') as f:\n",
        "                    job_postings_content.append(f.read())\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading job file {job_file_path}: {e}\")\n",
        "    print(f\"\\nSuccessfully read {len(job_postings_content)} individual job postings.\")\n",
        "    if job_postings_content:\n",
        "        print(\"First job posting content snippet:\")\n",
        "        print(job_postings_content[0][:200] + '...') # Print first 200 chars\n",
        "else:\n",
        "    print(\"\\nNo job files available to read.\")\n",
        "\n",
        "print(job_postings_content)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to access resume folder: /content/drive/MyDrive/SIH-Project/processed_resumes\n",
            "Attempting to access jobs folder: /content/drive/MyDrive/SIH-Project/processed-jobs\n",
            "\n",
            "Listing contents of 'processed resumes' folder:\n",
            "['structured_job_data.json']\n",
            "\n",
            "Listing contents of 'processed jobs' folder:\n",
            "['structured_job_data.json']\n",
            "\n",
            "Successfully read resume file: structured_job_data.json\n",
            "First few lines of resume content:\n",
            "{\"name\": \"Bhavesh Wadhwani\", \"email\": \"bhaveshwadhwanil4@gmail.com\", \"phone\": \"(+91) 899-911-6241\", \"linkedin\": null, \"experience\": [{\"title\": \"SENIOR CONSULTANT - DATA SCIENCE\", \"company\": \"Neosoft Technologies\", \"duration\": \"Dec. 2020 - Present\", \"description\": \"Managing international Clients as Data Science Consultant for E & Y One of BIG4 Consulting firms.\\nHelping top amongst fortune 100 clients to make better business decisions based on insights from their data in supply chain domain.\\nOptimize procurement process and demand planning cycle by forecasting sales across skus at various levels/ time intervals\\nIncreased overall sales by 15% with accurately predicting the skus selling more in seasons/festivals\\nBuilt and maintained scalable tools for forecasting, demand planning with managing the whole data science life cycle\\nSkills/Tools used in Job: Azure platform, Databricks, Azure ML services, Python, Git, Jupyter Notebooks, Python, Machine Learning, Deep Learning, Data Engineering, Docker\"}, {\"title\": \"DATA SCIENTIST\", \"company\": \"Nihilent Ltd.\", \"duration\": \"Nov. 2019 - Dec2020\", \"description\": \"Helping Top NBFC\\u2019s/ Banking Finance clients in India to make better business decisions based on insights from their data\\nDeveloped end-to-end machine learning prototypes and scaled them to run in production environments, increased efficiency by 23% on model performance\\nDesigned an overall architecture and pipelines of the Machine Learning / Deep Learning based applications with the micro-services architecture\\nImplemented solutions from scratch for data science, working on whole life cycle of solutions\\nDeployed scalable production models for internet scale data\\nSkills/Tools used in Job: GCP platform, Git, Jupyter, Python, Machine Learning, Google Bigquery, Deep Learning, Docker, Data Engineering\"}, {\"title\": \"DATA SCIENTIST\", \"company\": \"Infosys\", \"duration\": \"Dec. 2017 - Jun. 2019\", \"description\": \"Working with ONGC Client (Top 10 - Fortune 500) to reduce cost and improve efficiency for servers using data science\\nCertified from Infosys for Python, SQL, Machine Learning, Deep Learning\\nAs part of Infosys NIA OPS-Analytics team we target to improve performance and create high business value and we successfully reduced manual work to 60% by atomizing solutions\\nCleaned and Analyzed text data using Python, NLP techniques, ML Algorithms\\nImproved performance of servers by 8% and reduce critical alerts by 10% by using previous event alert log data using Machine Learning\"}, {\"title\": \"SOFTWARE ENGINEER - WEB DEVELOPER INTERN\", \"company\": \"Eventbeep Entertainment LLP\", \"duration\": \"June. 2017 - Dec. 2017\", \"description\": \"Woked ona product Ticketing platform for college and university events\\u201d\\nFull stack developer using technologies like Php, codeignitor framework, javascript, html, css, bootstrap.\\nResponsible for developing new features on website with leading a team of 5 interns.\\nFew key features in which | had contributed in the product were Integrating payment gateways to website, SMS and Email - integration for ticketing platform, built dynamic display for events with minimal latency.\"}], \"education\": [{\"degree\": \"B.E. IN INFORMATION TECHNOLOGY\", \"institution\": \"Maharashtra Institute of Technology (University of Pune)\", \"year\": \"June. 2013 - June. 2017\"}], \"skills\": [\"Python\", \"MS-SQL\", \"MySQL\", \"SQLite\", \"Mongo DB\", \"BigQuery\", \"Numpy\", \"SciPy\", \"Pandas\", \"Dask\", \"GeoPandas\", \"Sklearn\", \"NLTK\", \"OpenCyV\", \"Keras\", \"Tensorflow\", \"Azure ML\", \"Pytorch\", \"Azure ML Studio\", \"Azure ML\", \"GCP Al Platform\", \"AWS Sagemaker\", \"Docker\", \"Kubeflow\", \"Flask\", \"Plotly\", \"Matplotlib\", \"Seaborn\", \"Google Cloud Platform(GCP)\", \"Azure\", \"AWS\", \"Google Colab\", \"Heroku\", \"Jupyter Notebook\", \"Github\", \"VSCode IDE\", \"Machine Learning Algorithms\", \"Deep Learning Techinques\"]}\n",
            "\n",
            "Successfully read 8 individual job postings.\n",
            "First job posting content snippet:\n",
            "Organizational Skills, Creativity, Proactiveness, Positive Attitude, Interpersonal Skills, Stress Management, Adobe Creative Cloud, Microsoft Office Suite, Brand Management, Event Planning, Vendor Man...\n",
            "['Organizational Skills, Creativity, Proactiveness, Positive Attitude, Interpersonal Skills, Stress Management, Adobe Creative Cloud, Microsoft Office Suite, Brand Management, Event Planning, Vendor Management, Marketing, Graphic Design', 'Mental Healthcare, Trauma-Informed Care, EMDR, Social Work, Counseling, Psychotherapy, Case Management, Crisis Intervention, Clinical Documentation, Interpersonal Skills, Communication', 'Restaurant Operations Management, Customer Service', 'Elder Law, Estate Planning, Trusts and Estates, Medicaid Planning, Asset Protection, Estate Administration, Trust Administration, Legal Litigation, Advance Directives, Legal Document Drafting, Organizational Skills, Analytical Skills, Problem-Solving Skills, Communication', 'HVAC Systems, Mechanical Licensing, Commercial Equipment, Industrial Equipment', 'Data Science, Machine Learning, Applied Statistics, Python, SQL, Data Analysis, Data Visualization, Cloud Platforms, Natural Language Processing, Computer Vision, Time Series Analysis, Big Data Technologies, Version Control, Analytical Thinking, Problem Solving, Communication, Team Collaboration', 'Cybersecurity, Penetration Testing, Network Security, Web Application Security, Digital Forensics, Cryptography, Cloud Security, Linux, Networking, Scripting, Communication, Presentation Skills', 'Data Analysis, Financial Modeling, Process Improvement, Programming (Python, SQL, R), Quantitative Analysis, Project Management, Communication, Process Documentation, Renewable Energy Markets, Utility Programs, Data Management, Risk Management']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9649af61",
        "outputId": "a67dd23d-3a82-43e9-9d7d-241db98e24ff"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "print(job_postings_content)\n",
        "print(selected_resume_content)\n",
        "#\n",
        "# 3. Load a pre-trained Sentence-BERT model\n",
        "print(\"Loading Sentence-BERT model 'all-MiniLM-L6-v2'...\")\n",
        "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# 4. Generate the embedding for the selected resume content\n",
        "resume_embedding = None\n",
        "if selected_resume_content:\n",
        "    print(\"Generating embedding for the selected resume...\")\n",
        "    resume_embedding = model.encode(selected_resume_content)\n",
        "    print(f\"Resume embedding generated with shape: {resume_embedding.shape}\")\n",
        "else:\n",
        "    print(\"Warning: No resume content found. Please ensure the file reading step was successful (cell ID cde87e8e).\")\n",
        "\n",
        "# 5. Generate embeddings for all job postings\n",
        "job_embeddings = []\n",
        "if job_postings_content:\n",
        "    print(f\"Generating embeddings for {len(job_postings_content)} job postings...\")\n",
        "    job_embeddings = model.encode(job_postings_content)\n",
        "    print(f\"Job embeddings generated with shape: {job_embeddings.shape}\")\n",
        "else:\n",
        "    print(\"Warning: No job postings content found. Please ensure the file reading step was successful (cell ID cde87e8e).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Organizational Skills, Creativity, Proactiveness, Positive Attitude, Interpersonal Skills, Stress Management, Adobe Creative Cloud, Microsoft Office Suite, Brand Management, Event Planning, Vendor Management, Marketing, Graphic Design', 'Mental Healthcare, Trauma-Informed Care, EMDR, Social Work, Counseling, Psychotherapy, Case Management, Crisis Intervention, Clinical Documentation, Interpersonal Skills, Communication', 'Restaurant Operations Management, Customer Service', 'Elder Law, Estate Planning, Trusts and Estates, Medicaid Planning, Asset Protection, Estate Administration, Trust Administration, Legal Litigation, Advance Directives, Legal Document Drafting, Organizational Skills, Analytical Skills, Problem-Solving Skills, Communication', 'HVAC Systems, Mechanical Licensing, Commercial Equipment, Industrial Equipment', 'Data Science, Machine Learning, Applied Statistics, Python, SQL, Data Analysis, Data Visualization, Cloud Platforms, Natural Language Processing, Computer Vision, Time Series Analysis, Big Data Technologies, Version Control, Analytical Thinking, Problem Solving, Communication, Team Collaboration', 'Cybersecurity, Penetration Testing, Network Security, Web Application Security, Digital Forensics, Cryptography, Cloud Security, Linux, Networking, Scripting, Communication, Presentation Skills', 'Data Analysis, Financial Modeling, Process Improvement, Programming (Python, SQL, R), Quantitative Analysis, Project Management, Communication, Process Documentation, Renewable Energy Markets, Utility Programs, Data Management, Risk Management']\n",
            "{\"name\": \"Bhavesh Wadhwani\", \"email\": \"bhaveshwadhwanil4@gmail.com\", \"phone\": \"(+91) 899-911-6241\", \"linkedin\": null, \"experience\": [{\"title\": \"SENIOR CONSULTANT - DATA SCIENCE\", \"company\": \"Neosoft Technologies\", \"duration\": \"Dec. 2020 - Present\", \"description\": \"Managing international Clients as Data Science Consultant for E & Y One of BIG4 Consulting firms.\\nHelping top amongst fortune 100 clients to make better business decisions based on insights from their data in supply chain domain.\\nOptimize procurement process and demand planning cycle by forecasting sales across skus at various levels/ time intervals\\nIncreased overall sales by 15% with accurately predicting the skus selling more in seasons/festivals\\nBuilt and maintained scalable tools for forecasting, demand planning with managing the whole data science life cycle\\nSkills/Tools used in Job: Azure platform, Databricks, Azure ML services, Python, Git, Jupyter Notebooks, Python, Machine Learning, Deep Learning, Data Engineering, Docker\"}, {\"title\": \"DATA SCIENTIST\", \"company\": \"Nihilent Ltd.\", \"duration\": \"Nov. 2019 - Dec2020\", \"description\": \"Helping Top NBFC\\u2019s/ Banking Finance clients in India to make better business decisions based on insights from their data\\nDeveloped end-to-end machine learning prototypes and scaled them to run in production environments, increased efficiency by 23% on model performance\\nDesigned an overall architecture and pipelines of the Machine Learning / Deep Learning based applications with the micro-services architecture\\nImplemented solutions from scratch for data science, working on whole life cycle of solutions\\nDeployed scalable production models for internet scale data\\nSkills/Tools used in Job: GCP platform, Git, Jupyter, Python, Machine Learning, Google Bigquery, Deep Learning, Docker, Data Engineering\"}, {\"title\": \"DATA SCIENTIST\", \"company\": \"Infosys\", \"duration\": \"Dec. 2017 - Jun. 2019\", \"description\": \"Working with ONGC Client (Top 10 - Fortune 500) to reduce cost and improve efficiency for servers using data science\\nCertified from Infosys for Python, SQL, Machine Learning, Deep Learning\\nAs part of Infosys NIA OPS-Analytics team we target to improve performance and create high business value and we successfully reduced manual work to 60% by atomizing solutions\\nCleaned and Analyzed text data using Python, NLP techniques, ML Algorithms\\nImproved performance of servers by 8% and reduce critical alerts by 10% by using previous event alert log data using Machine Learning\"}, {\"title\": \"SOFTWARE ENGINEER - WEB DEVELOPER INTERN\", \"company\": \"Eventbeep Entertainment LLP\", \"duration\": \"June. 2017 - Dec. 2017\", \"description\": \"Woked ona product Ticketing platform for college and university events\\u201d\\nFull stack developer using technologies like Php, codeignitor framework, javascript, html, css, bootstrap.\\nResponsible for developing new features on website with leading a team of 5 interns.\\nFew key features in which | had contributed in the product were Integrating payment gateways to website, SMS and Email - integration for ticketing platform, built dynamic display for events with minimal latency.\"}], \"education\": [{\"degree\": \"B.E. IN INFORMATION TECHNOLOGY\", \"institution\": \"Maharashtra Institute of Technology (University of Pune)\", \"year\": \"June. 2013 - June. 2017\"}], \"skills\": [\"Python\", \"MS-SQL\", \"MySQL\", \"SQLite\", \"Mongo DB\", \"BigQuery\", \"Numpy\", \"SciPy\", \"Pandas\", \"Dask\", \"GeoPandas\", \"Sklearn\", \"NLTK\", \"OpenCyV\", \"Keras\", \"Tensorflow\", \"Azure ML\", \"Pytorch\", \"Azure ML Studio\", \"Azure ML\", \"GCP Al Platform\", \"AWS Sagemaker\", \"Docker\", \"Kubeflow\", \"Flask\", \"Plotly\", \"Matplotlib\", \"Seaborn\", \"Google Cloud Platform(GCP)\", \"Azure\", \"AWS\", \"Google Colab\", \"Heroku\", \"Jupyter Notebook\", \"Github\", \"VSCode IDE\", \"Machine Learning Algorithms\", \"Deep Learning Techinques\"]}\n",
            "Loading Sentence-BERT model 'all-MiniLM-L6-v2'...\n",
            "Model loaded successfully.\n",
            "Generating embedding for the selected resume...\n",
            "Resume embedding generated with shape: (768,)\n",
            "Generating embeddings for 8 job postings...\n",
            "Job embeddings generated with shape: (8, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8e27694",
        "outputId": "12c54ec5-b566-4cab-d686-208999bd0213"
      },
      "source": [
        "import json\n",
        "\n",
        "# 1. Extract and combine focused content from resume_data\n",
        "focused_resume_content = []\n",
        "\n",
        "# Extract skills\n",
        "if 'skills' in resume_data and isinstance(resume_data['skills'], list):\n",
        "    focused_resume_content.extend(resume_data['skills'])\n",
        "\n",
        "# Extract experience descriptions\n",
        "if 'experience' in resume_data and isinstance(resume_data['experience'], list):\n",
        "    for exp in resume_data['experience']:\n",
        "        if 'description' in exp:\n",
        "            focused_resume_content.append(exp['description'])\n",
        "\n",
        "focused_resume_content_str = ' '.join(focused_resume_content).strip()\n",
        "\n",
        "print(f\"\\nGenerated focused resume content (first 200 chars): {focused_resume_content_str[:200]}...\")\n",
        "\n",
        "# 2. Extract and combine focused content from job_postings_raw_data\n",
        "focused_job_contents = []\n",
        "for job_obj in job_postings_raw_data:\n",
        "    job_focused_text = []\n",
        "    if 'skills' in job_obj and isinstance(job_obj['skills'], list):\n",
        "        job_focused_text.extend(job_obj['skills'])\n",
        "    if 'responsibilities' in job_obj and isinstance(job_obj['responsibilities'], list):\n",
        "        job_focused_text.extend(job_obj['responsibilities'])\n",
        "    focused_job_contents.append(' '.join(job_focused_text).strip())\n",
        "\n",
        "print(f\"Generated {len(focused_job_contents)} focused job contents. First one (first 200 chars): {focused_job_contents[0][:200]}...\")\n",
        "\n",
        "# 3. Generate embedding for focused_resume_content\n",
        "focused_resume_embedding = None\n",
        "if focused_resume_content_str:\n",
        "    print(\"\\nGenerating embedding for focused resume content...\")\n",
        "    focused_resume_embedding = model.encode(focused_resume_content_str)\n",
        "    print(f\"Focused Resume embedding generated with shape: {focused_resume_embedding.shape}\")\n",
        "else:\n",
        "    print(\"Warning: No focused resume content found.\")\n",
        "\n",
        "# 4. Generate embeddings for focused_job_contents\n",
        "focused_job_embeddings = []\n",
        "if focused_job_contents:\n",
        "    print(f\"\\nGenerating embeddings for {len(focused_job_contents)} focused job postings...\")\n",
        "    focused_job_embeddings = model.encode(focused_job_contents)\n",
        "    print(f\"Focused Job embeddings generated with shape: {focused_job_embeddings.shape}\")\n",
        "else:\n",
        "    print(\"Warning: No focused job postings content found.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated focused resume content (first 200 chars): Python MS-SQL MySQL SQLite Mongo DB BigQuery Numpy SciPy Pandas Dask GeoPandas Sklearn NLTK OpenCyV Keras Tensorflow Azure ML Pytorch Azure ML Studio Azure ML GCP Al Platform AWS Sagemaker Docker Kube...\n",
            "Generated 8 focused job contents. First one (first 200 chars): Organizational Skills Creativity Proactiveness Positive Attitude Interpersonal Skills Stress Management Adobe Creative Cloud Microsoft Office Suite Brand Management Event Planning Vendor Management Ma...\n",
            "\n",
            "Generating embedding for focused resume content...\n",
            "Focused Resume embedding generated with shape: (768,)\n",
            "\n",
            "Generating embeddings for 8 focused job postings...\n",
            "Focused Job embeddings generated with shape: (8, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2453c64b",
        "outputId": "970efc8b-3d86-4075-da23-c094c820d7df"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Reshape focused_resume_embedding for compatibility with cosine_similarity if it's 1D\n",
        "if focused_resume_embedding.ndim == 1:\n",
        "    focused_resume_embedding_reshaped = focused_resume_embedding.reshape(1, -1)\n",
        "else:\n",
        "    focused_resume_embedding_reshaped = focused_resume_embedding\n",
        "\n",
        "# Calculate cosine similarity\n",
        "focused_similarity_scores = cosine_similarity(focused_resume_embedding_reshaped, focused_job_embeddings)\n",
        "\n",
        "print(\"Cosine Similarity Scores (Focused Resume vs. Focused Job Postings):\")\n",
        "print(focused_similarity_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity Scores (Focused Resume vs. Focused Job Postings):\n",
            "[[0.53909963 0.44110483 0.45857984 0.44021106 0.3879905  0.78032625\n",
            "  0.60558355 0.6707183 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4678e7b2",
        "outputId": "e374e686-9ff6-47cd-92df-75926eb77d53"
      },
      "source": [
        "num_top_matches = 5 # Display top 5 matches, or fewer if less are available\n",
        "similarity_threshold_low = 0.55 # Define lower bound for 'around 0.5'\n",
        "similarity_threshold_high = 0.95 # Define upper bound for 'around 0.5'\n",
        "\n",
        "# Create a list of (score, job_posting_raw_data) tuples\n",
        "# Ensure job_postings_raw_data and focused_similarity_scores match in length\n",
        "if len(job_postings_raw_data) == focused_similarity_scores.shape[1]:\n",
        "    scored_focused_jobs = []\n",
        "    for i in range(len(job_postings_raw_data)):\n",
        "        scored_focused_jobs.append((focused_similarity_scores[0, i], job_postings_raw_data[i]))\n",
        "\n",
        "    # Sort the jobs by similarity score in descending order\n",
        "    scored_focused_jobs.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    print(f\"\\nTop {min(num_top_matches, len(scored_focused_jobs))} Matching Job Postings (Focused Embeddings) around {similarity_threshold_low}-{similarity_threshold_high} similarity mark:\\n\")\n",
        "\n",
        "    filtered_jobs_count = 0\n",
        "    for score, job_data in scored_focused_jobs:\n",
        "        if similarity_threshold_low <= score <= similarity_threshold_high:\n",
        "            if filtered_jobs_count < num_top_matches:\n",
        "                filtered_jobs_count += 1\n",
        "                print(f\"--- Rank {filtered_jobs_count} ---\")\n",
        "                print(f\"Similarity Score: {score:.4f}\")\n",
        "                print(f\"Job Title: {job_data.get('job_title', 'N/A')}\")\n",
        "                print(f\"Company: {job_data.get('company_name', 'N/A')}\")\n",
        "\n",
        "                # Display skills if available\n",
        "                skills = job_data.get('skills', 'N/A')\n",
        "                if isinstance(skills, list):\n",
        "                    print(f\"Skills: {', '.join(skills)}\")\n",
        "                else:\n",
        "                    print(f\"Skills: {skills}\")\n",
        "\n",
        "                # Display a snippet of the original description\n",
        "                description_snippet = job_data.get('original_description', 'N/A')\n",
        "                if len(description_snippet) > 200:\n",
        "                    description_snippet = description_snippet[:200] + '...'\n",
        "                print(f\"Description Snippet: {description_snippet}\")\n",
        "                print(\"---------------------\\n\")\n",
        "            else:\n",
        "                break # Stop if we have found 5 matching jobs\n",
        "\n",
        "    if filtered_jobs_count == 0:\n",
        "        print(\"No job postings found within the specified similarity range.\")\n",
        "\n",
        "else:\n",
        "    print(\"Error: Mismatch between number of job postings and focused similarity scores.\")\n",
        "    print(f\"Jobs found: {len(job_postings_raw_data)}, Scores found: {focused_similarity_scores.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 Matching Job Postings (Focused Embeddings) around 0.55-0.95 similarity mark:\n",
            "\n",
            "--- Rank 1 ---\n",
            "Similarity Score: 0.7803\n",
            "Job Title: Data Scientist\n",
            "Company: N/A\n",
            "Skills: Data Science, Machine Learning, Applied Statistics, Python, SQL, Data Analysis, Data Visualization, Cloud Platforms, Natural Language Processing, Computer Vision, Time Series Analysis, Big Data Technologies, Version Control, Analytical Thinking, Problem Solving, Communication, Team Collaboration\n",
            "Description Snippet: N/A\n",
            "---------------------\n",
            "\n",
            "--- Rank 2 ---\n",
            "Similarity Score: 0.6707\n",
            "Job Title: Energy Program Operations Analyst\n",
            "Company: N/A\n",
            "Skills: Data Analysis, Financial Modeling, Process Improvement, Programming (Python, SQL, R), Quantitative Analysis, Project Management, Communication, Process Documentation, Renewable Energy Markets, Utility Programs, Data Management, Risk Management\n",
            "Description Snippet: N/A\n",
            "---------------------\n",
            "\n",
            "--- Rank 3 ---\n",
            "Similarity Score: 0.6056\n",
            "Job Title: Ethical Hacking Trainer\n",
            "Company: N/A\n",
            "Skills: Cybersecurity, Penetration Testing, Network Security, Web Application Security, Digital Forensics, Cryptography, Cloud Security, Linux, Networking, Scripting, Communication, Presentation Skills\n",
            "Description Snippet: N/A\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57e948a5",
        "outputId": "945830e1-6492-4c7e-f338-8b533adfc092"
      },
      "source": [
        "all_unique_skills = set()\n",
        "\n",
        "# 2. Extract skills from resume_data\n",
        "if 'skills' in resume_data and isinstance(resume_data['skills'], list):\n",
        "    all_unique_skills.update(resume_data['skills'])\n",
        "    print(f\"Added {len(resume_data['skills'])} skills from resume_data.\")\n",
        "else:\n",
        "    print(\"No skills found in resume_data or skills not in list format.\")\n",
        "\n",
        "# 3. Iterate through job_postings_raw_data and extract skills\n",
        "job_skills_count = 0\n",
        "for job_obj in job_postings_raw_data:\n",
        "    if 'skills' in job_obj and isinstance(job_obj['skills'], list):\n",
        "        all_unique_skills.update(job_obj['skills'])\n",
        "        job_skills_count += len(job_obj['skills'])\n",
        "print(f\"Added {job_skills_count} skills (including duplicates) from all job postings.\")\n",
        "\n",
        "# 4. Convert the set to a list and print summary\n",
        "all_unique_skills_list = list(all_unique_skills)\n",
        "print(f\"\\nTotal number of unique skills collected: {len(all_unique_skills_list)}\")\n",
        "print(f\"First 10 unique skills: {all_unique_skills_list[:10]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 38 skills from resume_data.\n",
            "Added 85 skills (including duplicates) from all job postings.\n",
            "\n",
            "Total number of unique skills collected: 114\n",
            "First 10 unique skills: ['Data Management', 'Plotly', 'Presentation Skills', 'Process Documentation', 'Cybersecurity', 'Web Application Security', 'Adobe Creative Cloud', 'NLTK', 'Mongo DB', 'Proactiveness']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "5761119b8aff4f85b78c76b1eba112a9",
            "e23ac789a9d4419989cd61f3f323e5a2",
            "6574bf30110742479521ffd17cf0a094",
            "be010bc32d04451bb6407623c09f7933",
            "8f39b82477974c1186675fca2aa85fee",
            "577a885b0ed94683a91915efa7f75061",
            "881f0a7fcc0344b7b21eac8be933168d",
            "cfe7dd7cbb9c40a9988de882b3824cb0",
            "058dc691c9f1498f9d8c9b97441dd75b",
            "2bac9d85163e4678ba073891e0a94e3c",
            "9a24c0a56de94b97a406b44d22c9a1db"
          ]
        },
        "id": "ce760f83",
        "outputId": "55cac7db-4c8d-45d5-e022-11581e74ebf4"
      },
      "source": [
        "print(f\"Generating embeddings for {len(all_unique_skills_list)} unique skills...\")\n",
        "skill_embeddings = model.encode(all_unique_skills_list, show_progress_bar=True)\n",
        "print(f\"Skill embeddings generated with shape: {skill_embeddings.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings for 114 unique skills...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5761119b8aff4f85b78c76b1eba112a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skill embeddings generated with shape: (114, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "a4873431dcd042e9b997e7e64f39ce46",
            "17e0adf5f0a949e3bafa2f447e361031",
            "0bb0824484b940af972dc921bed7b9f9",
            "f7be47b26de44eeba4211273f80e2dca",
            "568acc93c0e841aeae8c6ea94d3786c3",
            "63e37355d9e04800b2a05d74bd821781",
            "1d01693984d24265aca247e21334bc01",
            "4bce6fe302344a49a2c428aa13d8b721",
            "1f0f89773ee441858ce75850243e61cc",
            "adc7cb95be7b493ab13d136156b325fb",
            "5681020ee2694fde9b94141b3df3ef9d"
          ]
        },
        "id": "347bd2d2",
        "outputId": "b62fba61-dd19-483d-e6b0-4012697387cc"
      },
      "source": [
        "applicant_skills_for_embedding = []\n",
        "if 'skills' in resume_data and isinstance(resume_data['skills'], list):\n",
        "    applicant_skills_for_embedding = resume_data['skills']\n",
        "\n",
        "print(f\"Generating embeddings for {len(applicant_skills_for_embedding)} applicant skills...\")\n",
        "applicant_skill_embeddings = model.encode(applicant_skills_for_embedding, show_progress_bar=True)\n",
        "print(f\"Applicant skill embeddings generated with shape: {applicant_skill_embeddings.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings for 38 applicant skills...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4873431dcd042e9b997e7e64f39ce46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applicant skill embeddings generated with shape: (38, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c06ed71",
        "outputId": "289c1926-acec-4f90-d4bf-f6b7ea79f568"
      },
      "source": [
        "semantic_similarity_threshold = 0.5 # Define a semantic similarity threshold for individual skills\n",
        "\n",
        "print(f\"\\nIdentifying semantically missing skills for relevant job postings (semantic similarity threshold: {semantic_similarity_threshold}):\\n\")\n",
        "\n",
        "filtered_jobs_count = 0\n",
        "for score, job_data in scored_focused_jobs:\n",
        "    if 0.55 <= score <= 0.70:\n",
        "        if filtered_jobs_count < num_top_matches:\n",
        "            filtered_jobs_count += 1\n",
        "            print(f\"--- Rank {filtered_jobs_count} ---\")\n",
        "            print(f\"Overall Similarity Score: {score:.4f}\")\n",
        "            print(f\"Job Title: {job_data.get('job_title', 'N/A')}\")\n",
        "\n",
        "            job_skills_list = job_data.get('skills', [])\n",
        "            semantically_missing_skills = []\n",
        "\n",
        "            if isinstance(job_skills_list, list) and job_skills_list:\n",
        "                for job_skill in job_skills_list:\n",
        "                    # Get the embedding for the current job skill\n",
        "                    try:\n",
        "                        job_skill_index = all_unique_skills_list.index(job_skill)\n",
        "                        job_skill_embedding = skill_embeddings[job_skill_index]\n",
        "\n",
        "                        # Calculate cosine similarity between job_skill_embedding and all applicant_skill_embeddings\n",
        "                        if applicant_skill_embeddings.size > 0: # Ensure there are applicant skills to compare against\n",
        "                            # Reshape for cosine_similarity function if needed\n",
        "                            job_skill_embedding_reshaped = job_skill_embedding.reshape(1, -1)\n",
        "                            individual_skill_similarities = cosine_similarity(job_skill_embedding_reshaped, applicant_skill_embeddings)\n",
        "\n",
        "                            # Find the maximum similarity score for this job skill against any applicant skill\n",
        "                            max_similarity_to_applicant_skills = np.max(individual_skill_similarities)\n",
        "\n",
        "                            # If the maximum similarity is below the semantic threshold, consider it missing\n",
        "                            if max_similarity_to_applicant_skills < semantic_similarity_threshold:\n",
        "                                semantically_missing_skills.append(job_skill)\n",
        "                        else:\n",
        "                            # If no applicant skills, all job skills are effectively 'missing'\n",
        "                            semantically_missing_skills.append(job_skill)\n",
        "\n",
        "                    except ValueError:\n",
        "                        # This should ideally not happen if all job skills were added to all_unique_skills_list\n",
        "                        # but as a fallback, if a skill isn't in our embedded list, it's 'missing'\n",
        "                        semantically_missing_skills.append(job_skill)\n",
        "\n",
        "                if semantically_missing_skills:\n",
        "                    print(f\"Semantically missing skills for this role: {', '.join(semantically_missing_skills)}\")\n",
        "                else:\n",
        "                    print(\"No semantically missing skills identified for this role.\")\n",
        "            else:\n",
        "                print(\"No skills listed for this job posting or format is incorrect.\")\n",
        "            print(\"---------------------\\n\")\n",
        "        else:\n",
        "            break\n",
        "\n",
        "if filtered_jobs_count == 0:\n",
        "    print(\"No job postings found within the specified overall similarity range (0.45-0.55).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Identifying semantically missing skills for relevant job postings (semantic similarity threshold: 0.5):\n",
            "\n",
            "--- Rank 1 ---\n",
            "Overall Similarity Score: 0.6707\n",
            "Job Title: Energy Program Operations Analyst\n",
            "Semantically missing skills for this role: Financial Modeling, Process Improvement, Project Management, Communication, Process Documentation, Renewable Energy Markets, Utility Programs, Risk Management\n",
            "---------------------\n",
            "\n",
            "--- Rank 2 ---\n",
            "Overall Similarity Score: 0.6056\n",
            "Job Title: Ethical Hacking Trainer\n",
            "Semantically missing skills for this role: Cybersecurity, Penetration Testing, Network Security, Web Application Security, Linux, Networking, Communication, Presentation Skills\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content')\n",
        "from resume_parser import process\n",
        "process(\"resume.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EFpqTqJDVG8m",
        "outputId": "201e0f65-e7e6-430b-8601-386884ced828"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully.\n",
            "Gemini configured and model initialized.\n",
            "Text extraction module functions defined.\n",
            "Resume JSON schema defined.\n",
            "parse_resume_with_llm function defined.\n",
            "Text extracted successfully (first 500 characters):\n",
            " Bhavesh Wadhwani DATA SCIENTIST + GOOGLE CLOUD CERTIFIED - MICROSOFT CERTIFIED 0 (+91) 899-911-6241 | S%bhaveshwadhwanil4@gmail.com | @bhaveshwadhwani.github.io | @bhaveshwadhwani | §& bhaveshwadhwani Summary Results-oriented Data Scientist with 4.5+ years of work experience in the IT industry. Experienced in Machine-learning, Deep Learning, Com- puter Vision, Natural Language Processing (NLP), processing real-time data. Recently have verified my Data Science/Engineering skills too by passing th\n",
            "\n",
            "Parsed Resume Data:\n",
            " {\n",
            "  \"name\": \"Bhavesh Wadhwani\",\n",
            "  \"email\": \"bhaveshwadhwanil4@gmail.com\",\n",
            "  \"phone\": \"(+91) 899-911-6241\",\n",
            "  \"linkedin\": null,\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"title\": \"SENIOR CONSULTANT - DATA SCIENCE\",\n",
            "      \"company\": \"Neosoft Technologies\",\n",
            "      \"duration\": \"Dec. 2020 - Present\",\n",
            "      \"description\": \"Managing international Clients as Data Science Consultant for E & Y One of BIG4 Consulting firms. Helping top amongst fortune 100 clients to make better business decisions based on insights from their data in supply chain domain. Optimize procurement process and demand planning cycle by forecasting sales across skus at various levels/ time intervals Increased overall sales by 15% with accurately predicting the skus selling more in seasons/festivals Built and maintained scalable tools for forecasting, demand planning with managing the whole data science life cycle Skills/Tools used in Job: Azure platform, Databricks, Azure ML services, Python, Git, Jupyter Notebooks, Python, Machine Learning, Deep Learn- ing, Data Engineering, Docker\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"DATA SCIENTIST\",\n",
            "      \"company\": \"Nihilent Ltd.\",\n",
            "      \"duration\": \"Nov. 2019 - Dec2020\",\n",
            "      \"description\": \"Helping Top NBFC\\u2019s/ Banking Finance clients in India to make better business decisions based on insights from their data Developed end-to-end machine learning prototypes and scaled them to run in production environments, increased efficiency by 23% on model performance Designed an overall architecture and pipelines of the Machine Learning / Deep Learning based applications with the micro-services architec- ure Implemented solutions from scratch for data science, working on whole life cycle of solutions Deployed scalable production models for internet scale data Skills/Tools used in Job: GCP platform, Git, Jupyter, Python, Machine Learning, Google Bigquery, Deep Learning, Docker, Data Engineering\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"DATA SCIENTIST\",\n",
            "      \"company\": \"Infosys\",\n",
            "      \"duration\": \"Dec. 2017 - Jun. 2019\",\n",
            "      \"description\": \"Working with ONGC Client (Top 10 - Fortune 500) to reduce cost and improve efficiency for servers using data science Certified from Infosys for Python, SQL, Machine Learning, Deep Learning As part of Infosys NIA OPS-Analytics team we target to improve performance and create high business value and we successfully reduced manual work to 60% by atomizing solutions Cleaned and Analyzed text data using Python, NLP techniques, ML Algorithms Improved performance of servers by 8% and reduce critical alerts by 10% by using previous event alert log data using Machine Learning\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"SOFTWARE ENGINEER - WEB DEVELOPER INTERN\",\n",
            "      \"company\": \"Eventbeep Entertainment LLP\",\n",
            "      \"duration\": \"June. 2017 - Dec. 2017\",\n",
            "      \"description\": \"Woked ona product Ticketing platform for college and university events\\u201d Full stack developer using technologies like Php, codeignitor framework, javascript, html, css, bootstrap. Responsible for developing new features on website with leading a team of 5 interns. Few key features in which | had contributed in the product were Integrating payment gateways to website, SMS and Email - integration for ticketing platform, built dynamic display for events with minimal latency.\"\n",
            "    }\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"B.E. IN INFORMATION TECHNOLOGY\",\n",
            "      \"institution\": \"Maharashtra Institute of Technology (University of Pune)\",\n",
            "      \"year\": \"June. 2013 - June. 2017\"\n",
            "    }\n",
            "  ],\n",
            "  \"skills\": [\n",
            "    \"Python\",\n",
            "    \"MS-SQL\",\n",
            "    \"MySQL\",\n",
            "    \"SQLite\",\n",
            "    \"Mongo DB\",\n",
            "    \"BigQuery\",\n",
            "    \"Numpy\",\n",
            "    \"SciPy\",\n",
            "    \"Pandas\",\n",
            "    \"Dask\",\n",
            "    \"GeoPandas\",\n",
            "    \"Sklearn\",\n",
            "    \"NLTK\",\n",
            "    \"OpenCyV\",\n",
            "    \"Keras\",\n",
            "    \"Tensorflow\",\n",
            "    \"Azure ML\",\n",
            "    \"Pytorch\",\n",
            "    \"Azure ML Studio\",\n",
            "    \"GCP Al Platform\",\n",
            "    \"AWS Sagemaker\",\n",
            "    \"Docker\",\n",
            "    \"Kubeflow\",\n",
            "    \"Flask\",\n",
            "    \"Plotly\",\n",
            "    \"Matplotlib\",\n",
            "    \"Seaborn\",\n",
            "    \"Google Cloud Platform(GCP)\",\n",
            "    \"Azure\",\n",
            "    \"AWS\",\n",
            "    \"Google Colab\",\n",
            "    \"Heroku\",\n",
            "    \"Jupyter Notebook\",\n",
            "    \"Github\",\n",
            "    \"VSCode IDE\",\n",
            "    \"Machine Learning Algorithms\",\n",
            "    \"Deep Learning Techinques\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "    \"name\": \"Bhavesh Wadhwani\",\n",
            "    \"email\": \"bhaveshwadhwanil4@gmail.com\",\n",
            "    \"phone\": \"(+91) 899-911-6241\",\n",
            "    \"linkedin\": null,\n",
            "    \"experience\": [\n",
            "        {\n",
            "            \"title\": \"SENIOR CONSULTANT - DATA SCIENCE\",\n",
            "            \"company\": \"Neosoft Technologies\",\n",
            "            \"duration\": \"Dec. 2020 - Present\",\n",
            "            \"description\": \"Managing international Clients as Data Science Consultant for E & Y One of BIG4 Consulting firms. Helping top amongst fortune 100 clients to make better business decisions based on insights from their data in supply chain domain. Optimize procurement process and demand planning cycle by forecasting sales across skus at various levels/ time intervals Increased overall sales by 15% with accurately predicting the skus selling more in seasons/festivals Built and maintained scalable tools for forecasting, demand planning with managing the whole data science life cycle Skills/Tools used in Job: Azure platform, Databricks, Azure ML services, Python, Git, Jupyter Notebooks, Python, Machine Learning, Deep Learn- ing, Data Engineering, Docker\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"DATA SCIENTIST\",\n",
            "            \"company\": \"Nihilent Ltd.\",\n",
            "            \"duration\": \"Nov. 2019 - Dec2020\",\n",
            "            \"description\": \"Helping Top NBFC\\u2019s/ Banking Finance clients in India to make better business decisions based on insights from their data Developed end-to-end machine learning prototypes and scaled them to run in production environments, increased efficiency by 23% on model performance Designed an overall architecture and pipelines of the Machine Learning / Deep Learning based applications with the micro-services architec- ure Implemented solutions from scratch for data science, working on whole life cycle of solutions Deployed scalable production models for internet scale data Skills/Tools used in Job: GCP platform, Git, Jupyter, Python, Machine Learning, Google Bigquery, Deep Learning, Docker, Data Engineering\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"DATA SCIENTIST\",\n",
            "            \"company\": \"Infosys\",\n",
            "            \"duration\": \"Dec. 2017 - Jun. 2019\",\n",
            "            \"description\": \"Working with ONGC Client (Top 10 - Fortune 500) to reduce cost and improve efficiency for servers using data science Certified from Infosys for Python, SQL, Machine Learning, Deep Learning As part of Infosys NIA OPS-Analytics team we target to improve performance and create high business value and we successfully reduced manual work to 60% by atomizing solutions Cleaned and Analyzed text data using Python, NLP techniques, ML Algorithms Improved performance of servers by 8% and reduce critical alerts by 10% by using previous event alert log data using Machine Learning\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"SOFTWARE ENGINEER - WEB DEVELOPER INTERN\",\n",
            "            \"company\": \"Eventbeep Entertainment LLP\",\n",
            "            \"duration\": \"June. 2017 - Dec. 2017\",\n",
            "            \"description\": \"Woked ona product Ticketing platform for college and university events\\u201d Full stack developer using technologies like Php, codeignitor framework, javascript, html, css, bootstrap. Responsible for developing new features on website with leading a team of 5 interns. Few key features in which | had contributed in the product were Integrating payment gateways to website, SMS and Email - integration for ticketing platform, built dynamic display for events with minimal latency.\"\n",
            "        }\n",
            "    ],\n",
            "    \"education\": [\n",
            "        {\n",
            "            \"degree\": \"B.E. IN INFORMATION TECHNOLOGY\",\n",
            "            \"institution\": \"Maharashtra Institute of Technology (University of Pune)\",\n",
            "            \"year\": \"June. 2013 - June. 2017\"\n",
            "        }\n",
            "    ],\n",
            "    \"skills\": [\n",
            "        \"Python\",\n",
            "        \"MS-SQL\",\n",
            "        \"MySQL\",\n",
            "        \"SQLite\",\n",
            "        \"Mongo DB\",\n",
            "        \"BigQuery\",\n",
            "        \"Numpy\",\n",
            "        \"SciPy\",\n",
            "        \"Pandas\",\n",
            "        \"Dask\",\n",
            "        \"GeoPandas\",\n",
            "        \"Sklearn\",\n",
            "        \"NLTK\",\n",
            "        \"OpenCyV\",\n",
            "        \"Keras\",\n",
            "        \"Tensorflow\",\n",
            "        \"Azure ML\",\n",
            "        \"Pytorch\",\n",
            "        \"Azure ML Studio\",\n",
            "        \"GCP Al Platform\",\n",
            "        \"AWS Sagemaker\",\n",
            "        \"Docker\",\n",
            "        \"Kubeflow\",\n",
            "        \"Flask\",\n",
            "        \"Plotly\",\n",
            "        \"Matplotlib\",\n",
            "        \"Seaborn\",\n",
            "        \"Google Cloud Platform(GCP)\",\n",
            "        \"Azure\",\n",
            "        \"AWS\",\n",
            "        \"Google Colab\",\n",
            "        \"Heroku\",\n",
            "        \"Jupyter Notebook\",\n",
            "        \"Github\",\n",
            "        \"VSCode IDE\",\n",
            "        \"Machine Learning Algorithms\",\n",
            "        \"Deep Learning Techinques\"\n",
            "    ]\n",
            "}\n",
            "Successfully saved structured job data to 'structured_resume_data.json'\n"
          ]
        }
      ]
    }
  ]
}